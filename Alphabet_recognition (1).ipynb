{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D3EFoOO46Cof"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from keras.utils import to_categorical\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split #Machine lEARNING Model preparation\n",
        "from sklearn.utils import shuffle #For shuffling the Images data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "X_waRhHN6Hhk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4273ed83-cce8-4e10-c924-72d54b2c9ea0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# Mount your Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Your Google Drive files are now accessible in '/content/drive/My Drive/'\n",
        "\n",
        "# Specify the folder path where you want to upload the dataset\n",
        "folder_path = '/content/drive/My Drive/datasets/'\n",
        "\n",
        "# Upload the dataset to the specified folder in your Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Svv3wW916LEK"
      },
      "outputs": [],
      "source": [
        "# Replace 'your_uploaded_dataset.csv' with the actual filename of your dataset\n",
        "uploaded_dataset_path = folder_path + 'A_Z Handwritten Data.csv'\n",
        "\n",
        "# You can manually upload the dataset to this path via the Colab file explorer.\n",
        "\n",
        "# Load the dataset from your Google Drive into a Pandas DataFrame\n",
        "data = pd.read_csv(uploaded_dataset_path).astype('float32')\n",
        "\n",
        "# Now 'data' contains the dataset as a Pandas DataFrame\n",
        "print(data.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vci2jhuF6OuB"
      },
      "outputs": [],
      "source": [
        "X = data.drop('0',axis = 1)\n",
        "y = data['0'] #and put the 0 column in the label y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Rdkc_Sp6Q3S"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.2)\n",
        "\n",
        "#The below step  is to reshape the Image and Label data according to our requirement\n",
        "#shape size would be [28,28]\n",
        "\n",
        "train_x = np.reshape(train_x.values, (train_x.shape[0], 28,28))\n",
        "test_x = np.reshape(test_x.values, (test_x.shape[0], 28,28))\n",
        "print(\"Train data shape: \", train_x.shape)\n",
        "print(\"Test data shape: \", test_x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucby4f166TDZ"
      },
      "outputs": [],
      "source": [
        "word_dict = {0:'A',1:'B',2:'C',3:'D',4:'E',5:'F',6:'G',7:'H',8:'I',9:'J',10:'K',11:'L',12:'M',13:'N',14:'O',15:'P',16:'Q',17:'R',18:'S',19:'T',20:'U',21:'V',22:'W',23:'X', 24:'Y',25:'Z'}\n",
        "\n",
        "y_int = np.int0(y)\n",
        "count = np.zeros(26, dtype='int')\n",
        "print(count)\n",
        "for i in y_int:\n",
        "   count[i] +=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZ1XR8__6Tn6"
      },
      "outputs": [],
      "source": [
        "#We get the list named alphabets for the Comparision purpose\n",
        "alphabets = []\n",
        "for i in word_dict.values():\n",
        "    alphabets.append(i)\n",
        "alphabets[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8C6RnyO96aVC"
      },
      "outputs": [],
      "source": [
        "#We are ploting the bar graph of size 10 , 10\n",
        "#In which we can clearly see that Alphabets \"o\" frequency is greater than 50,000\n",
        "\n",
        "fig, ax = plt.subplots(1,1, figsize=(10,10))\n",
        "ax.barh(alphabets, count)\n",
        "plt.xlabel(\"Number of elements \")\n",
        "plt.ylabel(\"Alphabets\")\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Al4H2VyD6c7a"
      },
      "outputs": [],
      "source": [
        "\n",
        "shuff = shuffle(train_x[:10])\n",
        "fig, ax = plt.subplots(3,3, figsize = (10,10))\n",
        "axes = ax.flatten()\n",
        "for i in range(9):\n",
        "    shu = cv2.threshold(shuff[i], 30, 200, cv2.THRESH_BINARY)\n",
        "    axes[i].imshow(np.reshape(shuff[i], (28,28)), cmap=\"Greys\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkMKJgWd6e_Z"
      },
      "outputs": [],
      "source": [
        "#Data Reshaping\n",
        "#We changed the Images reshaping to \"New shape of train data:  (297960, 28, 28, 1)\"\n",
        "#For both Train and Test data\n",
        "train_X = train_x.reshape(train_x.shape[0],train_x.shape[1],train_x.shape[2],1)\n",
        "\n",
        "print(\"New shape of train data: \", train_X.shape)\n",
        "test_X = test_x.reshape(test_x.shape[0], test_x.shape[1], test_x.shape[2],1)\n",
        "print(\"New shape of test data: \", test_X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fU3ld7p16ffS"
      },
      "outputs": [],
      "source": [
        "#Here we convert the single float values to categorical values.\n",
        "#This is done as the CNN model takes input of labels & generates\n",
        "#the output as a vector of probabilities.\n",
        "train_yOHE = to_categorical(train_y, num_classes = 26, dtype='int')\n",
        "print(\"New shape of train labels: \", train_yOHE.shape)\n",
        "test_yOHE = to_categorical(test_y, num_classes = 26, dtype='int')\n",
        "print(\"New shape of test labels: \", test_yOHE.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EURnjrs6jhj"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras import backend as k\n",
        "import tensorflow\n",
        "\n",
        "# Tensor Flow has different features and CNN is one of them. Its getting the data as a input\n",
        "# Then its convolute the images with many different layers\n",
        "# After Convoluation there are pooling layers\n",
        "# The convolution layers are generally followed by maxpool layers that are used to reduce the\n",
        "# number of features extracted and ultimately the output of the maxpool and layers\n",
        "# and convolution layers are flattened into a vector of single dimension and are given as an\n",
        "#input to the Dense layer\n",
        "model = tf.keras.Sequential()\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64,activation =\"relu\"))\n",
        "model.add(Dense(128,activation =\"relu\"))\n",
        "model.add(Dense(26,activation =\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CRcz6Gn6kS6"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = tensorflow.keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_X, train_yOHE, epochs=15,  validation_data = (test_X,test_yOHE))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GMCUzthslyT"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "from IPython.display import Image\n",
        "\n",
        "# Assuming 'model' is your TensorFlow Keras model\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "# Display the generated image\n",
        "Image('model_plot.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VREOf316n-a"
      },
      "outputs": [],
      "source": [
        "#Here we will save the Model summar I am using my notebook in same folder So , I used the\n",
        "#Same path for this but you can save it on your selected location\n",
        "model.summary()\n",
        "model.save(r'model_hand.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_accuracy = [acc * 100 for acc in history.history['val_accuracy']]\n",
        "train_accuracy = [acc * 100 for acc in history.history['accuracy']]\n",
        "val_loss = history.history['val_loss']\n",
        "train_loss = history.history['loss']\n",
        "\n",
        "print(\"The validation accuracy is :\", val_accuracy)\n",
        "print(\"The training accuracy is :\", train_accuracy)\n",
        "print(\"The validation loss is :\", val_loss)\n",
        "print(\"The training loss is :\", train_loss)"
      ],
      "metadata": {
        "id": "6WSc8T8uOv53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLzusYSz6uLw"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have the following variables defined:\n",
        "# train_accuracy, val_accuracy, train_loss, val_loss\n",
        "\n",
        "# Find the epoch with the maximum validation accuracy\n",
        "best_val_acc_epoch = val_accuracy.index(max(val_accuracy))\n",
        "best_val_acc = max(val_accuracy)\n",
        "\n",
        "# Print the best validation accuracy and corresponding epoch\n",
        "print(f\"Best Validation Accuracy: {best_val_acc:} (Epoch {best_val_acc_epoch + 1})\")\n",
        "\n",
        "# Plotting Training and Validation Accuracy\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_accuracy, label='Training Accuracy', marker='o', linestyle='-')\n",
        "plt.plot(val_accuracy, label='Validation Accuracy', marker='o', linestyle='-')\n",
        "\n",
        "# Annotate the point with the best validation accuracy\n",
        "plt.scatter(best_val_acc_epoch, best_val_acc, color='red', label=f'Best Val Accuracy: {best_val_acc:}')\n",
        "plt.annotate(f'({best_val_acc_epoch + 1}, {best_val_acc:})',\n",
        "             xy=(best_val_acc_epoch, best_val_acc),\n",
        "             xytext=(best_val_acc_epoch - 3, best_val_acc - 0.05),\n",
        "             arrowprops=dict(facecolor='red', arrowstyle='->'))\n",
        "\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "\n",
        "# Plotting Training and Validation Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_loss, label='Training Loss', marker='o', linestyle='-')\n",
        "plt.plot(val_loss, label='Validation Loss', marker='o', linestyle='-')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Displaying the plots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu8-2MwT6xKg"
      },
      "outputs": [],
      "source": [
        "# Now we will finally have the things to show on the graph we are getting 9 images from\n",
        "# The train set\n",
        "fig, axes = plt.subplots(3,3, figsize=(8,9))\n",
        "axes = axes.flatten()\n",
        "# To showing the 9 images we will loop though the data from test model and will predict the\n",
        "# images on the basis of CNN model of keras/tensorflow.\n",
        "for i,ax in enumerate(axes):\n",
        "    img = np.reshape(test_X[i], (28,28))\n",
        "    ax.imshow(img, cmap=\"Greys\")\n",
        "\n",
        "    pred = word_dict[np.argmax(test_yOHE[i])]\n",
        "    ax.set_title(\"Prediction: \"+pred)\n",
        "    ax.grid()\n",
        "#Here we go below are the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaJLq4ZD61ZQ"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load your trained model and define the word_dict\n",
        "# You should replace 'model' and 'word_dict' with your actual model and dictionary\n",
        "\n",
        "def predict_alphabet(image_path):\n",
        "    # Load the uploaded image\n",
        "    img = cv2.imread(image_path)\n",
        "    img_copy = img.copy()\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (400, 440))\n",
        "\n",
        "    # Gaussian Method used for Blur checking\n",
        "    img_copy = cv2.GaussianBlur(img_copy, (7, 7), 0)\n",
        "    img_gray = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY)\n",
        "    _, img_thresh = cv2.threshold(img_gray, 100, 255, cv2.THRESH_BINARY_INV)\n",
        "    img_final = cv2.resize(img_thresh, (28, 28))\n",
        "    img_final = np.reshape(img_final, (1, 28, 28, 1))\n",
        "\n",
        "    img_pred = word_dict[np.argmax(model.predict(img_final))]\n",
        "    cv2.putText(img, \"New Prediction: \" + img_pred, (20, 410), cv2.FONT_HERSHEY_DUPLEX, 1.3, color=(255, 0, 30))\n",
        "    cv2_imshow(img)  # Use cv2_imshow() to display the image\n",
        "\n",
        "exit_flag = False\n",
        "\n",
        "while not exit_flag:\n",
        "    # Prompt the user to choose an action\n",
        "    print(\"Choose an action:\")\n",
        "    print(\"1. Upload an image for prediction\")\n",
        "    print(\"2. Quit\")\n",
        "\n",
        "    user_choice = input(\"Enter your choice (1/2): \")\n",
        "\n",
        "    if user_choice == \"1\":\n",
        "        try:\n",
        "            # Prompt the user to upload an image\n",
        "            print(\"Upload an image for prediction:\")\n",
        "            uploaded = files.upload()\n",
        "            if not uploaded:\n",
        "                print(\"No image uploaded. Please try again.\")\n",
        "                continue\n",
        "\n",
        "            # Get the first uploaded image (you can modify this logic to handle multiple images)\n",
        "            image_path = list(uploaded.keys())[0]\n",
        "\n",
        "            # Perform the prediction\n",
        "            predict_alphabet(image_path)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {str(e)}\")\n",
        "    elif user_choice == \"2\":\n",
        "        exit_flag = True\n",
        "        print(\"Exiting...\")\n",
        "    else:\n",
        "        print(\"Invalid choice. Please enter '1' to upload an image or '2' to quit.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}